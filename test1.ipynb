{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ada03b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dataset semanal con demanda intermitente\n",
    "data = {\n",
    "    'itemcode': ['SKU_001'] * 20,\n",
    "    'ds': pd.date_range(start='2024-01-01', periods=20, freq='W'),\n",
    "    'cantidad': [0, 0, 4, 0, 0, 5, 0, 0, 0, 3, 0, 0, 0, 7, 0, 0, 2, 0, 0, 6],\n",
    "    'mesaño': ['2024-' + str(d.isocalendar().week).zfill(2) for d in pd.date_range(start='2024-01-01', periods=20, freq='W')]\n",
    "}\n",
    "\n",
    "df_sku = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e130bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\maestria umsa\\Ciencia de datos introduccion\\2. Clase\\2. Workshop con Pandas\\Datos\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import CrostonOptimized\n",
    "\n",
    "\n",
    "\n",
    "def train_croston_statsforecast(df, freq='W', alpha=None):\n",
    "    \"\"\"\n",
    "    Entrena Croston clásico con statsforecast para un solo itemcode,\n",
    "    divide en train/test, predice y retorna test con columna Prediccion.\n",
    "\n",
    "    - df: DataFrame con columnas ['itemcode', 'ds', 'cantidad', 'mesaño']\n",
    "    - Retorna: df_test con misma estructura + columna Prediccion\n",
    "    \"\"\"\n",
    "    # **Corrección 1:** Añadir una aserción para verificar que solo hay un itemcode\n",
    "    assert df['itemcode'].nunique() == 1, \"El DataFrame debe contener un solo itemcode\"\n",
    "    \n",
    "    # Asegurar formatos\n",
    "    # **Corrección 2:** Usar .copy() para evitar SettingWithCopyWarning\n",
    "    df_copy = df.copy()\n",
    "    df_copy['ds'] = pd.to_datetime(df_copy['ds'])\n",
    "    df_copy = df_copy.sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "    # Separar en train/test\n",
    "    split_idx = int(len(df_copy) * 0.8)\n",
    "    df_train = df_copy.iloc[:split_idx].copy()\n",
    "    df_test = df_copy.iloc[split_idx:].copy()\n",
    "    h = len(df_test)\n",
    "\n",
    "    # Preparar datos para el modelo (cambiando nombres de columnas)\n",
    "    df_train_model = df_train.rename(columns={'itemcode': 'unique_id', 'cantidad': 'y'})[['unique_id', 'ds', 'y']]\n",
    "\n",
    "    model = CrostonOptimized()\n",
    "    sf = StatsForecast(models=[model], freq=freq, n_jobs=1)\n",
    "    \n",
    "    # 2. Entrenar el modelo final con todos los datos de entrenamiento\n",
    "    sf.fit(df=df_train_model)\n",
    "\n",
    "    # 3. Predecir los próximos h pasos\n",
    "    forecast = sf.predict(h=h)\n",
    "\n",
    "    # Agregar la columna Prediccion al dataframe de prueba original.\n",
    "    df_test['Prediccion'] = forecast['CrostonOptimized'].values\n",
    "\n",
    "    return df_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef9ead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Resultado de la predicción -----------------\n",
      "   itemcode         ds  cantidad   mesaño  Prediccion\n",
      "16  SKU_001 2024-04-28         2  2024-17    1.222513\n",
      "17  SKU_001 2024-05-05         0  2024-18    1.222513\n",
      "18  SKU_001 2024-05-12         0  2024-19    1.222513\n",
      "19  SKU_001 2024-05-19         6  2024-20    1.222513\n"
     ]
    }
   ],
   "source": [
    "# Llamar a la función con el DataFrame de ejemplo\n",
    "test_result = train_croston_statsforecast(df_sku)\n",
    "print(\"----------------- Resultado de la predicción -----------------\")\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0199ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import CrostonSBA # Importamos el modelo específico para SBA\n",
    "\n",
    "def train_sba_statsforecast(df, freq='W'):\n",
    "   \n",
    "    df_copy = df.copy()\n",
    " \n",
    "    # 3. Separar en conjuntos de entrenamiento y prueba\n",
    "    split_idx = int(len(df_copy) * 0.8)\n",
    "    df_train = df_copy.iloc[:split_idx].copy()\n",
    "    df_test = df_copy.iloc[split_idx:].copy()\n",
    "    h = len(df_test)\n",
    "\n",
    "    # 4. Preparar el DataFrame de entrenamiento para StatsForecast\n",
    "    df_train_model = df_train.rename(\n",
    "        columns={'itemcode': 'unique_id', 'cantidad': 'y'}\n",
    "    )[['unique_id', 'ds', 'y']]\n",
    "\n",
    "    \n",
    "    model = CrostonSBA()\n",
    "        \n",
    "    model_name = 'CrostonSBA'\n",
    "    \n",
    "    sf = StatsForecast(models=[model],freq=freq)\n",
    "        \n",
    "        # Entrenar el modelo final con todos los datos de entrenamiento\n",
    "    sf.fit(df=df_train_model)\n",
    "\n",
    "        # Predecir los próximos 'h' pasos\n",
    "    forecast = sf.predict(h=h)\n",
    "\n",
    "        # Agregar la columna de predicción al DataFrame de prueba\n",
    "    df_test['Prediccion'] = forecast[model_name].values\n",
    "\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4979702f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Resultado de la predicción -----------------\n",
      "   itemcode         ds  cantidad   mesaño  Prediccion\n",
      "16  SKU_001 2024-04-28         2  2024-17    1.277884\n",
      "17  SKU_001 2024-05-05         0  2024-18    1.277884\n",
      "18  SKU_001 2024-05-12         0  2024-19    1.277884\n",
      "19  SKU_001 2024-05-19         6  2024-20    1.277884\n"
     ]
    }
   ],
   "source": [
    "# Llamar a la función con el DataFrame de ejemplo\n",
    "test_result = train_sba_statsforecast(df_sku)\n",
    "print(\"----------------- Resultado de la predicción -----------------\")\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f9399fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import TSB\n",
    "\n",
    "# Implementación de MASE (Error Porcentual Absoluto Escalonado)\n",
    "def mase(y_true, y_pred, y_train):\n",
    "    \"\"\"\n",
    "    Calcula el Error Porcentual Absoluto Escalonado (MASE).\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.array): Valores reales.\n",
    "        y_pred (np.array): Valores pronosticados.\n",
    "        y_train (np.array): Valores del conjunto de entrenamiento.\n",
    "        \n",
    "    Returns:\n",
    "        float: El valor del MASE.\n",
    "    \"\"\"\n",
    "    # Numerador: Error absoluto de las predicciones\n",
    "    abs_errors = np.abs(y_true - y_pred)\n",
    "    \n",
    "    # Denominador: Error absoluto del pronóstico ingenuo (naive forecast)\n",
    "    # y_train[1:] - y_train[:-1] calcula las diferencias de un paso\n",
    "    denominator = np.mean(np.abs(y_train[1:] - y_train[:-1]))\n",
    "    \n",
    "    # Evita la división por cero si el denominador es 0\n",
    "    if denominator == 0:\n",
    "        return np.inf # O un valor muy grande para indicar un error\n",
    "    \n",
    "    return np.mean(abs_errors) / denominator\n",
    "\n",
    "def train_tsb_statsforecast_tuned(df, freq='W'):\n",
    "    \"\"\"\n",
    "    Entrena el modelo TSB con ajuste de parámetros (alpha_d y alpha_p) usando validación cruzada,\n",
    "    optimizando el MASE.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame de entrada con columnas ['itemcode', 'ds', 'cantidad'].\n",
    "        freq (str): Frecuencia de la serie temporal. Ejemplo: 'D', 'W', 'M'.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: El DataFrame de prueba con la columna 'Prediccion',\n",
    "                      'Mejor_MASE' y 'Mejores_Parametros'.\n",
    "    \"\"\"\n",
    "    # Asegurar formato correcto\n",
    "    df_copy = df.copy()\n",
    "    df_copy['ds'] = pd.to_datetime(df_copy['ds'])\n",
    "    df_copy = df_copy.sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "    # Separar train/test\n",
    "    split_idx = int(len(df_copy) * 0.8)\n",
    "    df_train = df_copy.iloc[:split_idx].copy()\n",
    "    df_test = df_copy.iloc[split_idx:].copy()\n",
    "    h = len(df_test)\n",
    "\n",
    "    # Preparar datos para StatsForecast\n",
    "    df_train_model = df_train.rename(\n",
    "        columns={'itemcode': 'unique_id', 'cantidad': 'y'}\n",
    "    )[['unique_id', 'ds', 'y']]\n",
    "    \n",
    "    # Convertir el conjunto de entrenamiento en un array para la función mase\n",
    "    y_train_array = df_train_model['y'].values\n",
    "    \n",
    "    # Grid de parámetros\n",
    "    alphas_d = np.linspace(0.01, 0.5, 10)\n",
    "    alphas_p = np.linspace(0.01, 0.5, 10)\n",
    "    \n",
    "    best_mase = float('inf')\n",
    "    best_params = {}\n",
    "    \n",
    "    # Búsqueda de hiperparámetros\n",
    "    for alpha_d in alphas_d:\n",
    "        for alpha_p in alphas_p:\n",
    "            model = TSB(alpha_d=alpha_d, alpha_p=alpha_p)\n",
    "            sf = StatsForecast(models=[model], freq=freq)\n",
    "            \n",
    "            cv_df = sf.cross_validation(df=df_train_model, h=h, n_windows=1)\n",
    "            \n",
    "            # Calcular MASE en lugar de MAPE\n",
    "            current_mase = mase(cv_df['y'].values, cv_df['TSB'].values, y_train_array)\n",
    "\n",
    "            if current_mase < best_mase:\n",
    "                best_mase = current_mase\n",
    "                best_params = {'alpha_d': alpha_d, 'alpha_p': alpha_p}\n",
    "\n",
    "    # Entrenar modelo final con mejores parámetros\n",
    "    final_model = TSB(alpha_d=best_params['alpha_d'], alpha_p=best_params['alpha_p'])\n",
    "    final_sf = StatsForecast(models=[final_model], freq=freq)\n",
    "    final_sf.fit(df=df_train_model)\n",
    "\n",
    "    # Predecir sobre h pasos\n",
    "    forecast = final_sf.predict(h=h)\n",
    "\n",
    "    # Agregar predicciones al test y los resultados\n",
    "    df_test = df_test.copy()\n",
    "    df_test['Prediccion'] = forecast['TSB'].values\n",
    "    \n",
    "    # Agregar las mejores métricas y parámetros para referencia\n",
    "    df_test['MASE'] = best_mase\n",
    "\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3c80f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   itemcode         ds  cantidad   mesaño  Prediccion      MASE\n",
      "16  SKU_001 2024-04-28         2  2024-17    0.199062  0.711773\n",
      "17  SKU_001 2024-05-05         0  2024-18    0.199062  0.711773\n",
      "18  SKU_001 2024-05-12         0  2024-19    0.199062  0.711773\n",
      "19  SKU_001 2024-05-19         6  2024-20    0.199062  0.711773\n"
     ]
    }
   ],
   "source": [
    "# Asegúrate de tener tu DataFrame llamado df_sku con columnas:\n",
    "# ['itemcode', 'ds', 'cantidad']\n",
    "\n",
    "resultado = train_tsb_statsforecast_tuned(df_sku)\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "849e5508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Implementación de MASE (Error Porcentual Absoluto Escalonado)\n",
    "def mase(y_true, y_pred, y_train):\n",
    "    \"\"\"\n",
    "    Calcula el Error Porcentual Absoluto Escalonado (MASE).\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.array): Valores reales.\n",
    "        y_pred (np.array): Valores pronosticados.\n",
    "        y_train (np.array): Valores del conjunto de entrenamiento.\n",
    "        \n",
    "    Returns:\n",
    "        float: El valor del MASE.\n",
    "    \"\"\"\n",
    "    # Numerador: Error absoluto de las predicciones\n",
    "    abs_errors = np.abs(y_true - y_pred)\n",
    "    \n",
    "    # Denominador: Error absoluto del pronóstico ingenuo (naive forecast)\n",
    "    denominator = np.mean(np.abs(y_train[1:] - y_train[:-1]))\n",
    "    \n",
    "    # Evita la división por cero\n",
    "    if denominator == 0:\n",
    "        return np.inf\n",
    "    \n",
    "    return np.mean(abs_errors) / denominator\n",
    "\n",
    "def train_prophet_tuned(df, freq='W'):\n",
    "    \"\"\"\n",
    "    Entrena el modelo Prophet con ajuste de parámetros (changepoint_prior_scale y seasonality_prior_scale)\n",
    "    usando validación cruzada, optimizando el MASE.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame de entrada con columnas ['itemcode', 'ds', 'cantidad'].\n",
    "        freq (str): Frecuencia de la serie temporal. Ejemplo: 'D', 'W', 'M'.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: El DataFrame de prueba con la columna 'Prediccion',\n",
    "                      'Mejor_MASE' y 'Mejores_Parametros'.\n",
    "    \"\"\"\n",
    "    # Asegurar formato correcto para Prophet\n",
    "    df_prophet = df.rename(columns={'ds': 'ds', 'cantidad': 'y'})\n",
    "    df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])\n",
    "\n",
    "    # Separar train/test\n",
    "    split_idx = int(len(df_prophet) * 0.8)\n",
    "    df_train = df_prophet.iloc[:split_idx].copy()\n",
    "    df_test = df_prophet.iloc[split_idx:].copy()\n",
    "    h = len(df_test)\n",
    "\n",
    "    # Convertir el conjunto de entrenamiento en un array para el cálculo del MASE\n",
    "    y_train_array = df_train['y'].values\n",
    "\n",
    "    # Grid de parámetros para Prophet\n",
    "    param_grid = {\n",
    "        'changepoint_prior_scale': [0.01, 0.05, 0.1, 0.2],\n",
    "        'seasonality_prior_scale': [0.1, 1.0, 5.0, 10.0],\n",
    "        'seasonality_mode': ['additive', 'multiplicative']\n",
    "    }\n",
    "    grid = ParameterGrid(param_grid)\n",
    "    \n",
    "    best_mase = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "    # Búsqueda de hiperparámetros usando validación cruzada de Prophet\n",
    "    for params in grid:\n",
    "        m = Prophet(**params)\n",
    "        m.fit(df_train)\n",
    "        \n",
    "        # Realizar validación cruzada\n",
    "        # initial: Periodo inicial para la ventana de entrenamiento\n",
    "        # period: Periodo entre las ventanas de corte\n",
    "        # horizon: Horizonte de pronóstico\n",
    "        cv_df = cross_validation(m, initial=f'{len(df_train)//2}{freq}', period=f'{h}{freq}', horizon=f'{h}{freq}')\n",
    "        \n",
    "        # Calcular MASE para esta combinación de parámetros\n",
    "        current_mase = mase(cv_df['y'].values, cv_df['yhat'].values, y_train_array)\n",
    "        \n",
    "        if current_mase < best_mase:\n",
    "            best_mase = current_mase\n",
    "            best_params = params\n",
    "\n",
    "    # Entrenar el modelo final con los mejores parámetros\n",
    "    final_model = Prophet(**best_params)\n",
    "    final_model.fit(df_train)\n",
    "\n",
    "    # Predecir sobre h pasos en el futuro\n",
    "    future = final_model.make_future_dataframe(periods=h, freq=freq, include_history=False)\n",
    "    forecast = final_model.predict(future)\n",
    "\n",
    "    # Agregar predicciones al DataFrame de test\n",
    "    df_test['Prediccion'] = forecast['yhat'].values\n",
    "\n",
    "    # Agregar las mejores métricas y parámetros para referencia\n",
    "    df_test['Mejor_MASE'] = best_mase\n",
    "\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf1e4ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:07:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
      "22:07:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n",
      "22:07:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.02it/s]\n",
      "22:07:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
      "22:07:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.04it/s]\n",
      "22:07:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "22:07:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "22:07:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "22:07:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.49it/s]\n",
      "22:07:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.79it/s]\n",
      "22:07:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.58it/s]\n",
      "22:07:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "22:07:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "22:07:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "22:07:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "22:07:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.64it/s]\n",
      "22:07:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.88it/s]\n",
      "22:07:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n",
      "22:07:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\n",
      "22:07:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.87it/s]\n",
      "22:07:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\n",
      "22:07:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.51it/s]\n",
      "22:07:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n",
      "22:07:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n",
      "22:07:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.18it/s]\n",
      "22:07:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.33it/s]\n",
      "22:07:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.30it/s]\n",
      "22:07:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "22:07:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.07it/s]\n",
      "22:07:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.00it/s]\n",
      "22:07:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.58it/s]\n",
      "22:07:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]22:07:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:07:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "22:08:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:08:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   itemcode         ds  y   mesaño  Prediccion  Mejor_MASE\n",
      "16  SKU_001 2024-04-28  2  2024-17    1.406585    0.818306\n",
      "17  SKU_001 2024-05-05  0  2024-18    1.432114    0.818306\n",
      "18  SKU_001 2024-05-12  0  2024-19    1.457642    0.818306\n",
      "19  SKU_001 2024-05-19  6  2024-20    1.483170    0.818306\n"
     ]
    }
   ],
   "source": [
    "# Asegúrate de tener tu DataFrame llamado df_sku con columnas:\n",
    "# ['itemcode', 'ds', 'cantidad']\n",
    "\n",
    "resultado = train_prophet_tuned(df_sku)\n",
    "print(resultado)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
